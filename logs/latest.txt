 ###########################################################
 #                    Initializing data                    #
 ###########################################################
 #            Files found locally! Importing...            #
 #                   PRE_INIT completed:                   #
 #                   - # features: 1600                    #
 #                   - # samples: 160000                   #
 ###########################################################
 ###########################################################
 #                Initializing data object                 #
 #              Using dtype dtype('float64')               #
 #                         ...done                         #
 ###########################################################
 ###########################################################
 #                Initializing data object                 #
 #              Using dtype dtype('float64')               #
 #                         ...done                         #
 ###########################################################
 ###########################################################
 #                Initializing data object                 #
 #              Using dtype dtype('float64')               #
 #                         ...done                         #
 ###########################################################
 ###########################################################
 #                Initializing data object                 #
 #              Using dtype dtype('float64')               #
 #                         ...done                         #
 ###########################################################



 ###########################################################
 #                   Creating batches...                   #
 #         2000 is not a proper divisor of 102600          #
 #                   using 2052 instead!                   #
 #                         ...done                         #
 ###########################################################
 #                 Learning rate: 0.001000                 #
 #                  number of neurons: 10                  #
 ###########################################################

 ###########################################################
 #                        EPOCH 1/1                        #
 ###########################################################
 #                                                         #
 #        Batch 1/2052: Loss: 0.71, Accuracy: 0.52         #
 #       Batch 206/2052: Loss: 0.56, Accuracy: 0.84        #
 #       Batch 411/2052: Loss: 0.40, Accuracy: 0.86        #
 #       Batch 616/2052: Loss: 0.23, Accuracy: 0.92        #
 #       Batch 821/2052: Loss: 0.31, Accuracy: 0.88        #
 #       Batch 1026/2052: Loss: 0.20, Accuracy: 0.92       #
 #       Batch 1231/2052: Loss: 0.13, Accuracy: 0.94       #
 #       Batch 1436/2052: Loss: 0.08, Accuracy: 1.00       #
 #       Batch 1641/2052: Loss: 0.07, Accuracy: 0.98       #
 #       Batch 1846/2052: Loss: 0.06, Accuracy: 0.96       #
 #       Batch 2051/2052: Loss: 0.10, Accuracy: 0.94       #
 #                                                         #
 #                                                         #
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
 #                                                         #
 #                                                         #
 #                        TEST-SET:                        #
 #                    - Loss: 0.081017                     #
 #                  - Accuracy: 0.977077                   #
 #                                                         #
 #                        CRIT-SET:                        #
 #                    - Loss: 0.426241                     #
 #                  - Accuracy: 0.841933                   #
 #                                                         #
 ###########################################################



 ###########################################################
 #                   Creating batches...                   #
 #         2000 is not a proper divisor of 102600          #
 #                   using 2052 instead!                   #
 #                         ...done                         #
 ###########################################################
 #                 Learning rate: 0.010000                 #
 #                  number of neurons: 10                  #
 ###########################################################

 ###########################################################
 #                        EPOCH 1/1                        #
 ###########################################################
 #                                                         #
 #        Batch 1/2052: Loss: 0.65, Accuracy: 0.50         #
 #       Batch 206/2052: Loss: 0.04, Accuracy: 1.00        #
 #       Batch 411/2052: Loss: 0.05, Accuracy: 0.98        #
 #       Batch 616/2052: Loss: 0.02, Accuracy: 1.00        #
 #       Batch 821/2052: Loss: 0.02, Accuracy: 1.00        #
 #       Batch 1026/2052: Loss: 0.03, Accuracy: 1.00       #
 #       Batch 1231/2052: Loss: 0.02, Accuracy: 1.00       #
 #       Batch 1436/2052: Loss: 0.01, Accuracy: 1.00       #
 #       Batch 1641/2052: Loss: 0.02, Accuracy: 1.00       #
 #       Batch 1846/2052: Loss: 0.01, Accuracy: 1.00       #
 #       Batch 2051/2052: Loss: 0.00, Accuracy: 1.00       #
 #                                                         #
 #                                                         #
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
 #                                                         #
 #                                                         #
 #                        TEST-SET:                        #
 #                    - Loss: 0.011911                     #
 #                  - Accuracy: 0.997231                   #
 #                                                         #
 #                        CRIT-SET:                        #
 #                    - Loss: 0.506652                     #
 #                  - Accuracy: 0.853800                   #
 #                                                         #
 ###########################################################



 ###########################################################
 #                   Creating batches...                   #
 #         2000 is not a proper divisor of 102600          #
 #                   using 2052 instead!                   #
 #                         ...done                         #
 ###########################################################
 #                 Learning rate: 0.100000                 #
 #                  number of neurons: 10                  #
 ###########################################################

 ###########################################################
 #                        EPOCH 1/1                        #
 ###########################################################
 #                                                         #
 #        Batch 1/2052: Loss: 0.64, Accuracy: 0.64         #
 #       Batch 206/2052: Loss: 0.01, Accuracy: 1.00        #
 #       Batch 411/2052: Loss: 0.01, Accuracy: 1.00        #
 #       Batch 616/2052: Loss: 0.01, Accuracy: 1.00        #
 #       Batch 821/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 1026/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1231/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1436/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1641/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1846/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 2051/2052: Loss: 0.00, Accuracy: 1.00       #
 #                                                         #
 #                                                         #
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
 #                                                         #
 #                                                         #
 #                        TEST-SET:                        #
 #                    - Loss: 0.003465                     #
 #                  - Accuracy: 0.999538                   #
 #                                                         #
 #                        CRIT-SET:                        #
 #                    - Loss: 0.557272                     #
 #                  - Accuracy: 0.866633                   #
 #                                                         #
 ###########################################################



 ###########################################################
 #                   Creating batches...                   #
 #         2000 is not a proper divisor of 102600          #
 #                   using 2052 instead!                   #
 #                         ...done                         #
 ###########################################################
 #                 Learning rate: 0.001000                 #
 #                 number of neurons: 100                  #
 ###########################################################

 ###########################################################
 #                        EPOCH 1/1                        #
 ###########################################################
 #                                                         #
 #        Batch 1/2052: Loss: 1.03, Accuracy: 0.76         #
 #       Batch 206/2052: Loss: 0.09, Accuracy: 0.96        #
 #       Batch 411/2052: Loss: 0.02, Accuracy: 1.00        #
 #       Batch 616/2052: Loss: 0.05, Accuracy: 1.00        #
 #       Batch 821/2052: Loss: 0.06, Accuracy: 0.96        #
 #       Batch 1026/2052: Loss: 0.02, Accuracy: 1.00       #
 #       Batch 1231/2052: Loss: 0.02, Accuracy: 1.00       #
 #       Batch 1436/2052: Loss: 0.04, Accuracy: 0.98       #
 #       Batch 1641/2052: Loss: 0.02, Accuracy: 1.00       #
 #       Batch 1846/2052: Loss: 0.01, Accuracy: 1.00       #
 #       Batch 2051/2052: Loss: 0.10, Accuracy: 0.98       #
 #                                                         #
 #                                                         #
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
 #                                                         #
 #                                                         #
 #                        TEST-SET:                        #
 #                    - Loss: 0.011883                     #
 #                  - Accuracy: 0.998231                   #
 #                                                         #
 #                        CRIT-SET:                        #
 #                    - Loss: 0.815734                     #
 #                  - Accuracy: 0.773667                   #
 #                                                         #
 ###########################################################



 ###########################################################
 #                   Creating batches...                   #
 #         2000 is not a proper divisor of 102600          #
 #                   using 2052 instead!                   #
 #                         ...done                         #
 ###########################################################
 #                 Learning rate: 0.010000                 #
 #                 number of neurons: 100                  #
 ###########################################################

 ###########################################################
 #                        EPOCH 1/1                        #
 ###########################################################
 #                                                         #
 #        Batch 1/2052: Loss: 0.56, Accuracy: 0.62         #
 #       Batch 206/2052: Loss: 0.02, Accuracy: 1.00        #
 #       Batch 411/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 616/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 821/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 1026/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1231/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1436/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1641/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1846/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 2051/2052: Loss: 0.00, Accuracy: 1.00       #
 #                                                         #
 #                                                         #
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
 #                                                         #
 #                                                         #
 #                        TEST-SET:                        #
 #                    - Loss: 0.003455                     #
 #                  - Accuracy: 0.999462                   #
 #                                                         #
 #                        CRIT-SET:                        #
 #                    - Loss: 0.701565                     #
 #                  - Accuracy: 0.824567                   #
 #                                                         #
 ###########################################################



 ###########################################################
 #                   Creating batches...                   #
 #         2000 is not a proper divisor of 102600          #
 #                   using 2052 instead!                   #
 #                         ...done                         #
 ###########################################################
 #                 Learning rate: 0.100000                 #
 #                 number of neurons: 100                  #
 ###########################################################

 ###########################################################
 #                        EPOCH 1/1                        #
 ###########################################################
 #                                                         #
 #        Batch 1/2052: Loss: 0.75, Accuracy: 0.72         #
 #       Batch 206/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 411/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 616/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 821/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 1026/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1231/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1436/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1641/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1846/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 2051/2052: Loss: 0.00, Accuracy: 1.00       #
 #                                                         #
 #                                                         #
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
 #                                                         #
 #                                                         #
 #                        TEST-SET:                        #
 #                    - Loss: 0.002706                     #
 #                  - Accuracy: 0.999769                   #
 #                                                         #
 #                        CRIT-SET:                        #
 #                    - Loss: 2.033483                     #
 #                  - Accuracy: 0.891933                   #
 #                                                         #
 ###########################################################



 ###########################################################
 #                   Creating batches...                   #
 #         2000 is not a proper divisor of 102600          #
 #                   using 2052 instead!                   #
 #                         ...done                         #
 ###########################################################
 #                 Learning rate: 0.001000                 #
 #                 number of neurons: 1000                 #
 ###########################################################

 ###########################################################
 #                        EPOCH 1/1                        #
 ###########################################################
 #                                                         #
 #        Batch 1/2052: Loss: 2.89, Accuracy: 0.50         #
 #       Batch 206/2052: Loss: 0.01, Accuracy: 1.00        #
 #       Batch 411/2052: Loss: 0.01, Accuracy: 1.00        #
 #       Batch 616/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 821/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 1026/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1231/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1436/2052: Loss: 0.69, Accuracy: 0.98       #
 #       Batch 1641/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1846/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 2051/2052: Loss: 0.00, Accuracy: 1.00       #
 #                                                         #
 #                                                         #
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
 #                                                         #
 #                                                         #
 #                        TEST-SET:                        #
 #                    - Loss: 0.011953                     #
 #                  - Accuracy: 0.998692                   #
 #                                                         #
 #                        CRIT-SET:                        #
 #                    - Loss: 3.397280                     #
 #                  - Accuracy: 0.668200                   #
 #                                                         #
 ###########################################################



 ###########################################################
 #                   Creating batches...                   #
 #         2000 is not a proper divisor of 102600          #
 #                   using 2052 instead!                   #
 #                         ...done                         #
 ###########################################################
 #                 Learning rate: 0.010000                 #
 #                 number of neurons: 1000                 #
 ###########################################################

 ###########################################################
 #                        EPOCH 1/1                        #
 ###########################################################
 #                                                         #
 #        Batch 1/2052: Loss: 9.23, Accuracy: 0.60         #
 #       Batch 206/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 411/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 616/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 821/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 1026/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1231/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1436/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1641/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1846/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 2051/2052: Loss: 0.00, Accuracy: 1.00       #
 #                                                         #
 #                                                         #
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
 #                                                         #
 #                                                         #
 #                        TEST-SET:                        #
 #                    - Loss: 0.001502                     #
 #                  - Accuracy: 0.999538                   #
 #                                                         #
 #                        CRIT-SET:                        #
 #                    - Loss: 2.462729                     #
 #                  - Accuracy: 0.759200                   #
 #                                                         #
 ###########################################################



 ###########################################################
 #                   Creating batches...                   #
 #         2000 is not a proper divisor of 102600          #
 #                   using 2052 instead!                   #
 #                         ...done                         #
 ###########################################################
 #                 Learning rate: 0.100000                 #
 #                 number of neurons: 1000                 #
 ###########################################################

 ###########################################################
 #                        EPOCH 1/1                        #
 ###########################################################
 #                                                         #
 #       Batch 1/2052: Loss: 186.13, Accuracy: 0.52        #
 #       Batch 206/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 411/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 616/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 821/2052: Loss: 0.00, Accuracy: 1.00        #
 #       Batch 1026/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1231/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1436/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1641/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 1846/2052: Loss: 0.00, Accuracy: 1.00       #
 #       Batch 2051/2052: Loss: 0.00, Accuracy: 1.00       #
 #                                                         #
 #                                                         #
 # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #
 #                                                         #
 #                                                         #
 #                        TEST-SET:                        #
 #                    - Loss: 0.000004                     #
 #                  - Accuracy: 1.000000                   #
 #                                                         #
 #                        CRIT-SET:                        #
 #                    - Loss: 1.609602                     #
 #                  - Accuracy: 0.935167                   #
 #                                                         #
 ###########################################################
